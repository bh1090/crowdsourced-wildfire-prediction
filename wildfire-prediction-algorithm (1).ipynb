{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10508760,"sourceType":"datasetVersion","datasetId":6505963}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, ConvLSTM2D, BatchNormalization, Conv3D\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n\n# Step 1: Locate and list files in the Kaggle input directory\ndata_dir = \"/kaggle/input/hawaiiwildfiredata/MODIS_C6_1_USA_contiguous_and_Hawaii_7d.csv\"\nfor dirname, _, filenames in os.walk(data_dir):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-26T22:04:32.739246Z","iopub.execute_input":"2025-01-26T22:04:32.739593Z","iopub.status.idle":"2025-01-26T22:04:51.260374Z","shell.execute_reply.started":"2025-01-26T22:04:32.739564Z","shell.execute_reply":"2025-01-26T22:04:51.259480Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Step 2: Load the wildfire dataset\n# Replace \"wildfire_dataset.csv\" with the actual filename\n# The dataset should contain time-series data in a spatiotemporal format\nfile_path= \"/kaggle/input/hawaiiwildfiredata/MODIS_C6_1_USA_contiguous_and_Hawaii_7d.csv\"\ndf = pd.read_csv(file_path)\n\nprint(\"Dataset Loaded\")\nprint(df.head())\n\nprint(f\"Generated Data Shape: {df.shape}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T22:11:16.317712Z","iopub.execute_input":"2025-01-26T22:11:16.318152Z","iopub.status.idle":"2025-01-26T22:11:16.336969Z","shell.execute_reply.started":"2025-01-26T22:11:16.318117Z","shell.execute_reply":"2025-01-26T22:11:16.336027Z"}},"outputs":[{"name":"stdout","text":"Dataset Loaded\n   latitude  longitude  brightness  scan  track    acq_date  acq_time  \\\n0  18.64694  -92.17207      317.04  1.24   1.11  2025-01-11       319   \n1  19.60189  -92.29641      311.96  1.23   1.10  2025-01-11       319   \n2  19.60610  -92.29182      312.81  1.22   1.10  2025-01-11       319   \n3  34.10029 -118.50399      342.61  1.02   1.01  2025-01-11       501   \n4  34.09873 -118.51461      357.69  1.02   1.01  2025-01-11       501   \n\n  satellite  confidence version  bright_t31    frp daynight  \n0         T          94  6.1NRT      290.38  21.13        N  \n1         T          77  6.1NRT      292.62  11.82        N  \n2         T          80  6.1NRT      292.42  13.06        N  \n3         T         100  6.1NRT      286.90  50.79        N  \n4         T         100  6.1NRT      288.73  83.89        N  \nGenerated Data Shape: (1666, 13)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df.describe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T22:11:18.387315Z","iopub.execute_input":"2025-01-26T22:11:18.387804Z","iopub.status.idle":"2025-01-26T22:11:18.408157Z","shell.execute_reply.started":"2025-01-26T22:11:18.387767Z","shell.execute_reply":"2025-01-26T22:11:18.406850Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.describe of       latitude  longitude  brightness  scan  track    acq_date  acq_time  \\\n0     18.64694  -92.17207      317.04  1.24   1.11  2025-01-11       319   \n1     19.60189  -92.29641      311.96  1.23   1.10  2025-01-11       319   \n2     19.60610  -92.29182      312.81  1.22   1.10  2025-01-11       319   \n3     34.10029 -118.50399      342.61  1.02   1.01  2025-01-11       501   \n4     34.09873 -118.51461      357.69  1.02   1.01  2025-01-11       501   \n...        ...        ...         ...   ...    ...         ...       ...   \n1661  19.43406 -103.48110      309.34  1.26   1.12  2025-01-18      1649   \n1662  19.43288 -103.48743      312.48  1.26   1.12  2025-01-18      1649   \n1663  18.82151 -103.69908      311.41  1.25   1.11  2025-01-18      1649   \n1664  18.82014 -103.70551      312.05  1.25   1.11  2025-01-18      1649   \n1665  18.77694 -103.74815      323.45  1.24   1.11  2025-01-18      1649   \n\n     satellite  confidence version  bright_t31    frp daynight  \n0            T          94  6.1NRT      290.38  21.13        N  \n1            T          77  6.1NRT      292.62  11.82        N  \n2            T          80  6.1NRT      292.42  13.06        N  \n3            T         100  6.1NRT      286.90  50.79        N  \n4            T         100  6.1NRT      288.73  83.89        N  \n...        ...         ...     ...         ...    ...      ...  \n1661         T          51  6.1NRT      298.18   5.72        D  \n1662         T          67  6.1NRT      298.43   8.98        D  \n1663         T          61  6.1NRT      298.66   7.71        D  \n1664         T          59  6.1NRT      299.91   8.32        D  \n1665         T          80  6.1NRT      301.27  20.63        D  \n\n[1666 rows x 13 columns]>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T22:11:47.678782Z","iopub.execute_input":"2025-01-26T22:11:47.679180Z","iopub.status.idle":"2025-01-26T22:11:47.706526Z","shell.execute_reply.started":"2025-01-26T22:11:47.679148Z","shell.execute_reply":"2025-01-26T22:11:47.705506Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1666 entries, 0 to 1665\nData columns (total 13 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   latitude    1666 non-null   float64\n 1   longitude   1666 non-null   float64\n 2   brightness  1666 non-null   float64\n 3   scan        1666 non-null   float64\n 4   track       1666 non-null   float64\n 5   acq_date    1666 non-null   object \n 6   acq_time    1666 non-null   int64  \n 7   satellite   1666 non-null   object \n 8   confidence  1666 non-null   int64  \n 9   version     1666 non-null   object \n 10  bright_t31  1666 non-null   float64\n 11  frp         1666 non-null   float64\n 12  daynight    1666 non-null   object \ndtypes: float64(7), int64(2), object(4)\nmemory usage: 169.3+ KB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# batch_size: Number of sequences in a batch.\n# time_steps: Number of time steps in each sequence.\n# height and width: Spatial dimensions of the grid.\n# channels: Number of features (e.g., brightness)\n# Each sequence represents grids of brightness values (or other spatial data) over a fixed number of time steps (time_steps).\ndef preprocess_data(df, time_steps, height, width, channels):\n    # Sort the data by acquisition date\n    df = df.sort_values(by='acq_date')\n\n    # Create a mapping for latitude and longitude to grid indices\n    df['lat_idx'] = ((df['latitude'] - df['latitude'].min()) /\n                     (df['latitude'].max() - df['latitude'].min()) * (height - 1)).astype(int)\n    df['lon_idx'] = ((df['longitude'] - df['longitude'].min()) /\n                     (df['longitude'].max() - df['longitude'].min()) * (width - 1)).astype(int)\n    # Group data into sequences of `time_steps`\n    sequences = []\n    grouped = df.groupby('acq_date')\n    group_keys = list(grouped.groups.keys())\n\n    if len(group_keys) <= time_steps:\n        raise ValueError(f\"Not enough unique dates to create sequences. \"\n                         f\"Unique dates: {len(group_keys)}, required: {time_steps + 1}\")\n\n    for i in range(len(group_keys) - time_steps):\n        # Initialize a grid for the current sequence\n        grid_data = np.zeros((time_steps, height, width, channels))\n        for t in range(time_steps):\n            date_key = group_keys[i + t]\n            daily_data = grouped.get_group(date_key)\n            for _, row in daily_data.iterrows():\n                # Fill grid cell with brightness value\n                grid_data[t, row['lat_idx'], row['lon_idx'], 0] = row['brightness']\n        sequences.append(grid_data)\n    \n    return np.array(sequences)\n\nprint(\"No Syntax errors\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:09:31.100880Z","iopub.execute_input":"2025-01-19T09:09:31.101399Z","iopub.status.idle":"2025-01-19T09:09:31.115168Z","shell.execute_reply.started":"2025-01-19T09:09:31.101352Z","shell.execute_reply":"2025-01-19T09:09:31.113800Z"}},"outputs":[{"name":"stdout","text":"No Syntax errors\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"time_steps = 7\nheight = 50\nwidth = 50\nchannels = 1\n\n# Preprocess data\ndata = preprocess_data(df, time_steps, height, width, channels).reshape((7, 50, 50))\nprint(f\"Processed Data Shape: {data.shape}\")\n\n# Check if data has enough samples\nif data.shape[0] < 2:\n    raise ValueError(\"Not enough samples in `data` for train-test split.\")\n\n# Split into training and testing sets\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Print shapes of training and testing data\nprint(f\"Training Data Shape: {train_data.shape}\")\nprint(f\"Testing Data Shape: {test_data.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:09:34.061713Z","iopub.execute_input":"2025-01-19T09:09:34.062079Z","iopub.status.idle":"2025-01-19T09:09:34.161703Z","shell.execute_reply.started":"2025-01-19T09:09:34.062046Z","shell.execute_reply":"2025-01-19T09:09:34.160732Z"}},"outputs":[{"name":"stdout","text":"Processed Data Shape: (7, 50, 50)\nTraining Data Shape: (5, 50, 50)\nTesting Data Shape: (2, 50, 50)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Step 4: Build the ConvLSTM Model\n\nfrom keras.layers import Lambda\n\ndef build_model(input_shape):\n    inputs = Input(shape=input_shape)  # Input: (time_steps, height, width, channels)\n    x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(inputs)\n    x = BatchNormalization()(x)\n    x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True)(x)\n    x = BatchNormalization()(x)\n    x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=False)(x)\n    x = BatchNormalization()(x)\n    # Use a Lambda layer to add the depth dimension\n    x = Lambda(lambda y: tf.expand_dims(y, axis=-1))(x)\n    outputs = Conv3D(filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n    model = Model(inputs, outputs)\n    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n    return model\n\n# Create the model\ninput_shape = (time_steps, height, width, channels)\nprint(input_shape)\nmodel = build_model(input_shape)\n\n# Display model summary\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:09:37.108758Z","iopub.execute_input":"2025-01-19T09:09:37.109122Z","iopub.status.idle":"2025-01-19T09:09:37.278339Z","shell.execute_reply.started":"2025-01-19T09:09:37.109075Z","shell.execute_reply":"2025-01-19T09:09:37.277341Z"}},"outputs":[{"name":"stdout","text":"(7, 50, 50, 1)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv_lstm2d_3 (\u001b[38;5;33mConvLSTM2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m150,016\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv_lstm2d_4 (\u001b[38;5;33mConvLSTM2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m295,168\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv_lstm2d_5 (\u001b[38;5;33mConvLSTM2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m295,168\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │              \u001b[38;5;34m28\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv_lstm2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,016</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv_lstm2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv_lstm2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m741,148\u001b[0m (2.83 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">741,148</span> (2.83 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m740,764\u001b[0m (2.83 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">740,764</span> (2.83 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nfrom keras.callbacks import EarlyStopping\n\n# Step 1: Reshape the data\ntrain_data = np.random.random((250, 50, 50))  # Example data\ntrain_data_reshaped = train_data.reshape((50, 5, 50, 50, 1))  # Reshape into (50, 5, 50, 50, 1)\n\n# Verify the reshaped data\nprint(f\"Reshaped train_data shape: {train_data_reshaped.shape}\")  # Should be (50, 5, 50, 50, 1)\n\n# Step 2: Slice the data for input and output\ntrain_inputs = train_data_reshaped[:, :-1]  # Exclude the last timestep for input\ntrain_targets = train_data_reshaped[:, 1:]  # Exclude the first timestep for target\n\n# Verify the shapes\nprint(f\"Train inputs shape: {train_inputs.shape}\")  # Should be (50, 4, 50, 50, 1)\nprint(f\"Train targets shape: {train_targets.shape}\")  # Should be (50, 4, 50, 50, 1)\n\n\n# Step 3: Train the model\nhistory = model.fit(\n    train_inputs,  # Input: (batch_size, timesteps, height, width, channels)\n    train_targets,  # Target: (batch_size, timesteps, height, width, channels)\n    validation_split=0.2,  # 20% of data for validation\n    epochs=50,\n    batch_size=4,  # Batch size for training\n    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)],  # Early stopping\n    verbose=2\n)","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-01-30T01:03:37.785538Z","iopub.execute_input":"2025-01-30T01:03:37.785918Z","iopub.status.idle":"2025-01-30T01:03:54.723853Z","shell.execute_reply.started":"2025-01-30T01:03:37.785881Z","shell.execute_reply":"2025-01-30T01:03:54.722006Z"}},"outputs":[{"name":"stdout","text":"Reshaped train_data shape: (50, 5, 50, 50, 1)\nTrain inputs shape: (50, 4, 50, 50, 1)\nTrain targets shape: (50, 4, 50, 50, 1)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-06f6f13ed06a>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Step 3: Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Input: (batch_size, timesteps, height, width, channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Target: (batch_size, timesteps, height, width, channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# Step 6: Evaluate the Model\ntest_loss, test_accuracy = model.evaluate(test_data[:, :-1], test_data[:, 1:], verbose=0)\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Accuracy: {test_accuracy}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 7: Save the Model\nmodel.save(\"/kaggle/working/wildfire_convlstm_model.h5\")\nprint(\"Model Saved\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:08:35.763897Z","iopub.status.idle":"2025-01-19T09:08:35.764258Z","shell.execute_reply":"2025-01-19T09:08:35.764130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 8: Visualize Predictions\n# Pick a random test sample and visualize input vs. prediction\ndef visualize_prediction(model, test_sample):\n    prediction = model.predict(test_sample[None, :-1])\n    plt.figure(figsize=(10, 5))\n    for t in range(time_steps - 1):\n        plt.subplot(2, time_steps - 1, t + 1)\n        plt.imshow(test_sample[t, :, :, 0], cmap=\"hot\")\n        plt.title(f\"Time {t}\")\n        plt.axis(\"off\")\n    for t in range(time_steps - 1):\n        plt.subplot(2, time_steps - 1, time_steps - 1 + t + 1)\n        plt.imshow(prediction[0, t, :, :, 0], cmap=\"hot\")\n        plt.title(f\"Predicted {t}\")\n        plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n# Visualize a random test sample\nrandom_idx = random.randint(0, len(test_data) - 1)\nvisualize_prediction(model, test_data[random_idx])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:08:35.765151Z","iopub.status.idle":"2025-01-19T09:08:35.765442Z","shell.execute_reply":"2025-01-19T09:08:35.765323Z"}},"outputs":[],"execution_count":null}]}